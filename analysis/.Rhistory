probs <- c(0,.2,.3,.75)
hyps <- permn(probs) # Generates all permutations, where order doesn't matter it is 4x3x2x1
prior <- rep(1/24) # Entropy if we know nothing is 0.19
cat_entropy(prior)
update_probs <- function(prior,choice,outcome) {
# x, below, is a list of probabilities under a specific hypothesis
#Likelihood function is a zero for all hypotheses incompatible with the outcome
#and 1 otherwise
likelihood <- function(this_hyp,this_choice,this_outcome) {
if (this_outcome==this_choice){
likelihood[this_hyp] <- 1
} else {
likelihood <- 0
}
}
likes <- sapply(hyps,function(h) {likelihood(h,choice,outcome)})
unnp <- likes*prior
z <- sum(unnp)
unnp/z
}
post <- update_probs(prior,choice=1,outcome=0)
print(post)
update_probs <- function(prior,choice,outcome) {
# x, below, is a list of probabilities under a specific hypothesis
#Likelihood function is a zero for all hypotheses incompatible with the outcome
#and 1 otherwise
likelihood <- function(this_hyp,this_choice,this_outcome) {
prob_this_outcome <- (this_hyp[this_choice]*this_outcome) + (1-this_hyp[this_choice]*(1-this_outcome))
}
likes <- sapply(hyps,function(h) {likelihood(h,choice,outcome)})
unnp <- likes*prior
z <- sum(unnp)
unnp/z
}
post <- update_probs(prior,choice=1,outcome=0)
print(post)
cat_entropy(post)
log(24)
log2(24)
# First we want the probability of each outcome in each hyp
# Then we take the weighted sum over hypothesis probabilities
expected_outcome <- function(i,ph) {
sum(hyps[i])*ph
}
print(expected_outcome(2,post))
# First we want the probability of each outcome in each hyp
# Then we take the weighted sum over hypothesis probabilities
expected_outcome <- function(i,ph) {
sum(sapply(hyps, function(hyp) {hyp[i]})*ph) # the sapply results in a vector of 24. sapply loops over column and applies a function to each element
}
print(expected_outcome(2,post))
expected_entropy <- function(choice,p_hyps) {
pwin <- expected_outcome(choice,p_hyps)
cat_entropy(pwin)
}
print(expected_entropy(2,post))
#For steph 2
library(igraph)
library(tidyverse)
nodes<-c('Preference','Character','Closer','Knowledge','Visible','Choice')
graph<-matrix(c(0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,1,
0,0,0,0,0,0), ncol = 6, byrow=T)
G<-graph.adjacency(graph)
View(G)
V(G)$label<-V(G)$name<-nodes
V(G)$size <- 50
V(G)$color <- 'white'
E(G)$color <- 'black'
E(G)$width <- 2
plot(G)
?igraph
V(G)$color <- 'blue'
E(G)$color <- 'black'
E(G)$width <- 2
plot(G)
V(G)$color <- 'white'
E(G)$color <- 'red'
E(G)$width <- 2
plot(G)
#I figured its easier to think about in the form of a data frame
#So we have a column indexing the state for each cause using a factor (0,1)
#And a column for the probabilities for each unique combination
pChoice<-data.frame(expand.grid(list(Preference=c(0,1),
Character=c(0,1),
Closer=c(0,1),
Knowledge=c(0,1),
Visible = c(0,1)))) %>%
mutate(Preference = factor(Preference, levels = c(0,1),
labels = c('Absent','Hotdog')),
Character = factor(Character, levels = c(0,1),
labels = c('Lazy','Sporty')),
Closer = factor(Closer, levels = c(0,1),
labels = c('Pizza','Hotdog')),
Knowledge = factor(Knowledge, levels = c(0,1),
labels = c('No','Yes')),
Visible = factor(Visible, levels = c(0,1),
labels = c('Pizza','Hotdog')),
p_choose_hotdog = NA)
View(pChoice)
head(pChoice)
#Default preference for hotdog
baserate<-.5
#Strength of preference, strength of character
strengths<-list(preference=.5, character=.5)
#preference and character match only promote hotdog choice so long as the person either
#(a) knows the area or (b) can see the hotdog
tmp1<- pChoice$Knowledge=='Yes' | pChoice$Visible=='Hotdog'
#character match only promotes pizza choice so long as the person
#(a) knows the area or (b) can see the hotdog
tmp2<-pChoice$Knowledge=='Yes' | pChoice$Visible=='Pizza'
pChoice$p_choose_hotdog<-(1-(1-baserate) *
(1-strengths[['preference']]*as.numeric(pChoice$Preference=='Hotdog')*tmp1) *
#preference for hotdog pushes toward hotdog
(1-strengths[['character']]* as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Hotdog' |
#character match to distance to hotdog pushes toward hotdog
pChoice$Character=='Sporty' & pChoice$Closer=='Pizza')*tmp1)) *
#end of the noisy OR of generative causes
(1-strengths[['character']] * as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Pizza' |
#character match to distance to pizza pushes toward pizza
pChoice$Character=='Sporty' & pChoice$Closer=='Hotdog') * tmp2)
View(pChoice)
#Here's how it looks
pChoice
#Anc here's an example of using it to maker a basic counterfactual explanation type model
#Let's suppose a person chooses pizza in situation 15
case<-cbind(pChoice[15,], Choice='Pizza')
case
#Was it reasonably to be expected given the situation (in this case yes)
p_actual<-1-case$p_choose_hotdog
?unlist
#What features of the situation contributed most to its being selected?
#counterfactual contrasts:
p_counterfactual<-1-unlist(c(pChoice %>% filter(Preference!=case$Preference,
Character==case$Character,
Closer ==case$Closer,
Knowledge==case$Knowledge,
Visible==case$Visible) %>% select(preference=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character!=case$Character,
Closer ==case$Closer,
Knowledge==case$Knowledge,
Visible==case$Visible) %>% select(character=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character==case$Character,
Closer !=case$Closer,
Knowledge==case$Knowledge,
Visible==case$Visible) %>% select(closer=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character==case$Character,
Closer ==case$Closer,
Knowledge!=case$Knowledge,
Visible==case$Visible) %>% select(knowledge=p_choose_hotdog),
pChoice %>% filter(Preference==case$Preference,
Character==case$Character,
Closer ==case$Closer,
Knowledge==case$Knowledge,
Visible!=case$Visible) %>% select(visible=p_choose_hotdog)))
View(case)
dependence<-p_actual-p_counterfactual
#In this case we might reasonably blame her lazy character or the fact that the pizza was closer
Collapse
View(case)
View(pChoice)
dependence
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_push * char_push
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
pref_match_hotdog <- as.numeric(pChoice$Preference=='Hotdog')
char_match_hotdog <- as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Hotdog' |
pChoice$Character=='Sporty' & pChoice$Closer=='Pizza')
char_match_pizza <- as.numeric(pChoice$Character=='Lazy' & pChoice$Closer=='Pizza' |
#character match to distance to pizza pushes toward pizza
pChoice$Character=='Sporty' & pChoice$Closer=='Hotdog')
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
#preference and character match only promote hotdog choice so long as the person either
#(a) knows the area or (b) can see the hotdog ie generative ie things that make you want hotdog
prom_hotdog <- pChoice$Knowledge=='Yes' | pChoice$Visible=='Hotdog'
#character match only promotes pizza choice so long as the person
#(a) knows the area or (b) can see the hotdog ie preventative factor ie things that amke you want pizza
prom_pizza <- pChoice$Knowledge=='Yes' | pChoice$Visible=='Pizza'
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_push * char_push
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
# My meddling
hotdog_promotion <- function(char, pref, baserate) {
pref_prom_hotdog <- 1 - pref * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - char * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(0.5,0.5,0.5))
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(strengths[['character']], strengths[['preference']], baserate))
pChoice$prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate))
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate))
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion(c(strengths[['character']], strengths[['preference']], baserate)))
# My meddling
hotdog_promotion <- function() {
pref_prom_hotdog <- 1 - strengths[['preference']] * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - strengths[['character']] * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1-char*char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion())
# My meddling
hotdog_promotion <- function() {
pref_prom_hotdog <- 1 - strengths[['preference']] * pref_match_hotdog * prom_hotdog
char_prom_hotdog <- 1 - strengths[['character']] * char_match_hotdog * prom_hotdog
noisyOR <- 1-(1-baserate)
hotdog_score <- noisyOR * pref_prom_hotdog * char_prom_hotdog
pizza_score <- 1- strengths[['character']] *char_match_pizza * prom_pizza
p_choose_hotdog <- hotdog_score * pizza_score
return (p_choose_hotdog)
}
prob_choose_hotdog <- sapply(pChoice, hotdog_promotion())
22/110
2.002/10.10
5.005/10.01
2.005/10.1
2.002/10.1
52/110
exp(100)
exp(1)
runif(4)
sessionInfo()
sessionInfo()
sessionInfo()
install.packages("afex")
install.packages("faux")
library(broom, tidyverse, faux, afex)
library(broom)
library(faux)
library(afex)
R.version()
R.Version()
.libPaths()
.libPaths()
R.Version()
# ------- Prelims -----------
library(tidyverse)
library(ggplot2)
# ----------- Define an example prior df -------------------------
# Here define two causal vars and an exogenous noise variable for each (i.e. var epsilon A goes with A)
# in the exp setting this is 0.5
p_A <- c(.1,.9) # ie A usually has value 1... base rate for cause
p_epsA <- c(.7,.3) #... most of the time the noise var for a doesn't occur. for a to work it needs a and exp a. a is usually present but ogten doesnt work cos of noise term not working
p_B <- c(.8,.2) # B rarely fires 1...
p_epsB <- c(.3,.7) # but when it does it is strong
# And wrap them into a df called prior. Later the function should take dfs of this format:
# i.e. any number of causes as the rows, and the probs of them taking 0 and 1 as cols
params <- data.frame(rbind(p_A, p_epsA, p_B, p_epsB))
colnames(params) <- c(0,1)
# Other values set outside for now
N_cf <- 1000L # How many counterfactual samples to draw
s <- .7 # Stability
n_causes <- nrow(params)
causes <- rownames(params)
# Make a df of all combinations of variable settings
df <- expand.grid(rep(list(c(0,1)),n_causes), KEEP.OUT.ATTRS = F)
# ... with variables as the column names
colnames(df) <- causes
worlds <- nrow(df)
View(df)
structure <- 'disjunctive'
if (structure=="disjunctive") {
df$E <- as.numeric((df[1] & df[2]) | (df[3] & df[4]))
}
# Can replace with this - if rename - it is deterministic - literally gives specific outcome for set 3 causes, needs actual input. mechanical tell syou whether effects occurred given setting
# df$effect <- max( c(min(c1,e1), min(c2,e2), min(c3, e3), min(c2*c3, e23))) # BUT SAME PROBLEM - HOW TO AUTOMATICALLY DEAL WITH ANY NUMBER OF CAUSES?
mat <- as.matrix(df[,1:4])
View(mat)
# df2 <- as.matrix(df, dimnames=NULL)
# dimnames = list(c(1:16), c(causes))
# Replace every cell with the relevant indexed edge strength from params
for (k in 1:worlds){
for (cause in causes) {
a <- params[cause,df[k,cause]+1] # It needs the '+1' because r indexes from 1 not 0
mat[k,cause] <- a # ((then sometimes #*df[k,cause] if do at same time as structure but change later if need))
}
}
View(mat)
View(params)
# For each row of df, the prior is now the product of the same row of df2
df$Pr <- apply(mat, 1, prod) # parameter of the model
sum(df$Pr)
# Then loop to calculate cfs and assign causal responsibility
# Loop through possible world settings
for (c_ix in 1:worlds)
setwd("/Users/stephaniedroop/Documents/GitHub/TuringToM")
# Run wrangling and analysis script for Survey 1 ('S1'), the question generating phase
source("S1.r")
setwd("/Users/stephaniedroop/Documents/GitHub/TuringToM/analysis")
# Run wrangling and analysis script for Survey 1 ('S1'), the question generating phase
source("S1.r")
# Run wrangling and analysis script for Survey 2 ('S2'), the question rating phase
source("S2.r")
# Run script for visualisation for reporting S2 results, Fig.2 in paper
source("S2_latervis.r")
# Run script for wrangling and analysis for Survey 4 ('S4') for the voice assistants and the LLMs
source("S4_VA.r")
source("S4_LLM.r")
View(S4_rationale)
exp(0.5)
log(1.65)
getwd
getwd()
# Data needed - read in
coded1 <- read.csv('../data/coded1.csv') # file received by email from rater and saved into the data folder
coded2 <- read.csv('../data/coded2.csv') # file received by email from rater and saved into the data folder
S4coded <- read.csv('../data/S4coded.csv') # my own ratings - tbd if use or not
View(coded1)
View(coded2)
View(S4coded)
coded1[is.na(coded1)] <- 0
coded2[is.na(coded2)] <- 0
S4coded[is.na(S4coded)] <- 0
cats <- c('a', 'b', 'c', 'd', 'e')
colnames(S4coded[6:10]) <- cats
View(S4coded)
cats <- c('a', 'b', 'c', 'd', 'e', 'f')
colnames(S4coded[5:10]) <- cats
# Reorder by random column
S4coded <- order(S4coded$X, decreasing = F)
S4coded <- read.csv('../data/S4coded.csv') # my own ratings - tbd if use or not
S4coded[is.na(S4coded)] <- 0
# Reorder by random column
S4coded <- S4coded %>% order(X, decreasing = F)
# Load libraries
library(tidyverse)
# Reorder by random column
S4coded <- S4coded %>% order(X, decreasing = F)
# Reorder by random column
S4coded <- S4coded %>% order(S4coded$X, decreasing = F)
?sort
sort(S4coded$X)
S4coded %>% sort(S4coded$X)
S4coded %>% sort(S4coded$X, decreasing = 'F')
S4coded[order(S4coded$X),]
S4coded[order(S4coded$X),]
View(S4coded)
S4coded[order(S4coded$X),]
S4coded <- S4coded[order(S4coded$X),]
# Reorder by random column
coded1 <- coded1[order(coded1$X.1),]
coded2 <- coded2[order(coded2$X.1),]
#
S4coded <- S4coded %>% select(3,5:10)
coded1 <- coded1 %>% select(4,5:10)
coded2 <- coded2 %>% select(4,5:10)
colnames(coded1) <- c('Response', cats)
colnames(coded2) <- c('Response', cats)
colnames(S4coded) <- c('Response', cats)
# Function to get kappa from a contingency table
get_kappa <- function(matrix) {
#checkmate::assert_matrix(matrix)
stopifnot("input must be single matrix" = is.matrix(matrix))
diags <- diag(matrix)
N <- sum(matrix)
row.marginal.props <- rowSums(matrix)/N
col.marginal.props <- colSums(matrix)/N
# Compute kappa
Po <- sum(diags)/N
Pe <- sum(row.marginal.props*col.marginal.props)
k <- (Po - Pe)/(1 - Pe)
}
matr <- matrix(nrow = length(cats), ncol = length(cats))
colnames(matr) <- cats
rownames(matr) <- cats
# Replace NAs with 0s
matr[is.na(matr)] <- 0
View(matr)
#---------- Loop without asymmetric modification.    ------------
n_exps <- nrow(coded1) # How many explanations. We checked idat and vdat are the same length and order elsewhere so ok to assume it here
allocate_points <- function(vdat2, idat2) {
for (exp in 1:n_exps)
{
# Pull out v and i's whole rows of their separate ratings for the same explanation
vexp <- vdat2[exp,]
iexp <- idat2[exp,]
# Pull out just the ratings without the text response
vrat <- vexp[2:7]
irat <- iexp[2:7]
# Get total in vrat row and irat row. The point for each explanation will be divided by this
vsum <- sum(vrat)
isum <- sum(irat)
point <- 1/(vsum*isum) #
# Get positions where v and i gave a rating, giving numerical position in vector
v <- which(vrat!=0) # 2 3 5
i <- which(irat!=0) # 2 5
# Now find that place in the matrice and add point to it
matr[v, i] <- matr[v, i] + point
}
matr <- round(matr, digits = 1)
# Get kappa using function
k <- get_kappa(matr)
print(k) # It is 0.611 for the real data of me and Valtteri
}
# Now do this for each pair of coders
s_1 <- allocate_points(S4coded, coded1)
s_2 <- allocate_points(S4coded, coded2)
c1_c2 <- allocate_points(coded1, coded2)
exp <- 1
# Pull out v and i's whole rows of their separate ratings for the same explanation
vexp <- vdat2[exp,]
vdat2 <- S4coded
idat2 <- coded1
# Pull out v and i's whole rows of their separate ratings for the same explanation
vexp <- vdat2[exp,]
View(vexp)
iexp <- idat2[exp,]
View(iexp)
# Pull out just the ratings without the text response
vrat <- vexp[2:7]
View(vrat)
irat <- iexp[2:7]
View(irat)
# Get total in vrat row and irat row. The point for each explanation will be divided by this
vsum <- sum(vrat)
isum <- sum(irat)
point <- 1/(vsum*isum) #
# Get positions where v and i gave a rating, giving numerical position in vector
v <- which(vrat!=0) # 2 3 5
i <- which(irat!=0) # 2 5
# Now find that place in the matrice and add point to it
matr[v, i] <- matr[v, i] + point
View(matr)
View(matr)
View(vrat)
exp <- 118
# Pull out v and i's whole rows of their separate ratings for the same explanation
vexp <- vdat2[exp,]
iexp <- idat2[exp,]
View(iexp)
View(vexp)
# Pull out just the ratings without the text response
vrat <- vexp[2:7]
irat <- iexp[2:7]
# Get total in vrat row and irat row. The point for each explanation will be divided by this
vsum <- sum(vrat)
isum <- sum(irat)
point <- 1/(vsum*isum) #
# Get positions where v and i gave a rating, giving numerical position in vector
v <- which(vrat!=0) # 2 3 5
i <- which(irat!=0) # 2 5
# Now find that place in the matrice and add point to it
matr[v, i] <- matr[v, i] + point
View(matr)
# Now find that place in the matrice and add point to it
matr[v, i] <- matr[v, i] + point
# Now do this for each pair of coders
s_1 <- allocate_points(S4coded, coded1)
s_2 <- allocate_points(S4coded, coded2) #
c1_c2 <- allocate_points(coded1, coded2)
# Now do this for each pair of coders
s_1 <- allocate_points(S4coded, coded1) # 0.28
s_2 <- allocate_points(S4coded, coded2) # 0.29
c1_c2 <- allocate_points(coded1, coded2) # 0.36
sum(coded1$a)
for (j in cats)
{
cor <- cor(coded1$j, coded2$j)
print(cor)
}
cor(coded1$a,coded2$a)
cor(coded1$b,coded2$b)
cor(coded1$c,coded2$c)
cor(coded1$d,coded2$d)
cor(coded1$e,coded2$e)
cor(coded1$f,coded2$f)
coded1$e
sum(coded1$e)
sum(coded2$e)
sum(S4coded$e)
# Neil and Steph
cor(S4coded$a,coded2$a) # 0.58
cor(S4coded$b,coded2$b) # 0.77
cor(S4coded$c,coded2$c) # 0.86
cor(S4coded$d,coded2$d) # 0.64
cor(S4coded$e,coded2$e) # 0.2 - it is this column - Nic had 29, Neil had 12, I had 6
cor(S4coded$f,coded2$f)
# Nic and Steph
cor(coded1$a,S4coded$a) # 0.58
cor(coded1$b,S4coded$b) # 0.77
cor(coded1$c,S4coded$c) # 0.86
cor(coded1$d,S4coded$d) # 0.64
cor(coded1$e,S4coded$e) # 0.2 - it is this column - Nic had 29, Neil had 12, I had 6
cor(coded1$f,S4coded$f) # 0.78
